{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kIqgkMgEXab"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree, ensemble\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Use the breast cancer data set from Homework 0 to create a training set.\n",
    "Recall that the label is 0 if the patient has breast cancer and 1 otherwise.\n",
    "Compute the base rate of cancer occurrence over the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
    "q = np.where(target == 0)[0]\n",
    "len(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On random seeds:** Many functions in scikit-learn, including models as well as utilities,\n",
    "use randomization. For ease of grading, we will fix a random seed (we will use 101 throughout)\n",
    "so as to make behavior deterministic. This can generally be done by passing in `random_state=101` to\n",
    "the function; please consult documentation if unsure. Note to peer graders: this is purely for grading\n",
    "convenience. Do not penalize harshly if the random seed has not been set properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) The goal is to build a decision tree that, based on the other features in the set,\n",
    "predicts whether or not a patient has cancer.  So this is a classification problem.\n",
    "Using tree.DecisionTreeClassifier and other functions in the scikit-learn library, one can\n",
    "build a decision tree and calculate both its training accuracy when fitted to the entire data set\n",
    "as well as its accuracy using 10-fold cross validation (which gives a better idea of true accuracy).\n",
    "\n",
    "Vary the depth of your decision tree (use max_depth = $1, 2, \\dots, 10$) and plot both training\n",
    "accuracy and cross-validated accuracy (as a function of the depth, on the x-axis). Use 101 as your\n",
    "random seed. Plot both curves on the same plot and use a legend to label them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Now try the random forest classifier of the scikit-learn library and use the best\n",
    "depth you get from (b) as max_depth. Vary the number of trees in the forest via the parameter\n",
    "n_estimators and plot its 10-fold cross-validated accuracy (use n_estimators = $1, 2, \\dots, 20$).\n",
    "Again, use 101 as your random seed. Do you see an improvement using random forests versus\n",
    "using a single tree? (Note: use the n_estimators=1 result as the result for a single tree.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Using the method for building a decision tree you used in part (b), build a tree\n",
    "but randomly hold out a $.2$,$.4$,$.6$, and $.8$ fraction of the data set (so you \n",
    "will need to build 4 different trees for each depth value). Use 101 as your random seed for both\n",
    "the train-test split as well as the decision tree.\n",
    "For each fraction held out, plot a curve of the test accuracy (the accuracy on the held-out\n",
    "set) against depth. You should have four curves. Plot them all on the same plot and use\n",
    "a legend to label them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1-solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
